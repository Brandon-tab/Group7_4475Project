Survial
size <- nrow(Survial)
training <- sample(seq(size,size*0.7,replace = F))
train <- Survial[training,]
test <- Survial[-training,]
model <- rpart(Survived~Age+Pclass+Embarked,data = train)
prp(model,fallen.leaves = T)
#Confustion Matrix
#Advanced Evulation
require(rpart)
require(rpart.plot)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category", "Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Avg_Utilization_Ratio ~ Total_Revolving_Bal + Util_Rank + Income_Category,
data = train_data,
method = "class")
# 可视化决策树
rpart.plot(Tree,
type = 3,
extra = 104,               # 显示每个类别的比例
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
rpart.plot(Tree)
require(rpart)
require(rpart.plot)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category", "Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Avg_Utilization_Ratio ~ Total_Revolving_Bal + Util_Rank + Income_Category,
data = train_data,
method = "class")
# 可视化决策树
rpart.plot(Tree,
type = 3,
extra = 104,               # 显示每个类别的比例
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category", "Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Avg_Utilization_Ratio ~ Total_Revolving_Bal + Util_Rank + Income_Category,
data = train_data,
method = "class")
# 可视化决策树
rpart.plot(Tree,
shadow.col = "gray",
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category", "Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Avg_Utilization_Ratio ~ Total_Revolving_Bal + Util_Rank + Income_Category,
data = train_data,
method = "class")
prp(Tree,fallen.leaves = T)
# 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Pclass+Income_Category,data = train_data)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
prp(Tree,fallen.leaves = T)
# 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
type = 3,
extra = 104,               # 显示每个类别的比例
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category+Avg_Utilization_Ratio,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Avg_Utilization_Ratio+Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
#data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(42)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
#data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(12)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
#data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(20)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
#data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(35)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,      # 叶子节点在底部
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",    # 使用红-黄-绿调色板
shadow.col = "gray",        # 添加阴影效果
digits = 2)                 # 保留两位小数
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(35)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 去除缺失值
#data_clean <- na.omit(data_clean)
# 设置随机种子以便重现
set.seed(35)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(38)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(43)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(17)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(24)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(29)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
require(rpart)
require(rpart.plot)
# 假设 Transform 是您的数据框
treeData <- Transform
# 选择相关的列
data_clean <- treeData[, c("Total_Revolving_Bal", "Util_Rank", "Income_Category","Avg_Utilization_Ratio")]
# 设置随机种子以便重现
set.seed(38)
# 划分数据集
index <- sample(1:nrow(data_clean), 0.7 * nrow(data_clean))  # 70% 用于训练
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
# 构建决策树模型
Tree <- rpart(Util_Rank~Total_Revolving_Bal+Income_Category,data = train_data)
rpart.plot(Tree,
fallen.leaves = TRUE,
main = "Decision Tree for Credit Utilization Behavior",
box.palette = "RdYlGn",
shadow.col = "gray",
digits = 2)
